{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f6a246-26d5-4d6d-b839-6f5590bdba4c",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP): Bag-of-words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee7f5f-4bf0-49bf-9e13-677290fa301d",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8f724-ba4c-4279-b88a-4dd6e79d7f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "plt.style.use('seaborn-pastel')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8047181-73f9-4b1d-98aa-e72a4b6677ec",
   "metadata": {},
   "source": [
    "## Read in csv data\n",
    "Steam is a video game digital distribution service with a vast community of gamers globally. A lot of gamers write reviews on the game page and have the option of choosing whether they would recommend this game to others or not.  \n",
    "**review_id** --> Unique ID for each review  \n",
    "**title** --> Title of the game  \n",
    "**year** --> Year in which the review was posted  \n",
    "**user_review** --> Full Text of the review posted by a user  \n",
    "**user_suggestion** --> (Target) Game marked Recommended(1) and Not Recommended(0) by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b2a01-9ec0-41e8-a88d-a5f60e216364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steam = pd.read_csv(\"https://raw.githubusercontent.com/BaroqueObama/hhs-ws-bag-of-words/main/steam.csv\",encoding='ISO-8859-1') # encoding='ISO-8859-1' allows us to read unicode characters without issue\n",
    "display(steam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432a8e8-426e-408b-9fe5-e44f3baad4c0",
   "metadata": {},
   "source": [
    "### Drop uneeded columns (review_id, title, year) and NaN values if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65bce3-f0fa-4773-b69a-a8489b0b162d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steam.drop(columns=steam.columns[0:3],inplace=True)\n",
    "steam.dropna(axis=0,inplace=True)\n",
    "display(steam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be481dc1-3bca-4106-9c23-4962c554bfb3",
   "metadata": {},
   "source": [
    "### Plot the distribution between Recommended and Not Recommended game reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5bbe1d-1dbe-4774-b432-d7fc2f13689e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = steam[steam.columns[1]].value_counts().plot(kind='bar', title='Count of Game Reviews by Recommendation', figsize=(10, 5))\n",
    "ax.set_xlabel('Recommend = 1, Not Recommend = 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce9aa6-912a-4a3d-bb57-cd7ccb302fa5",
   "metadata": {},
   "source": [
    "## Tokenize a string by splitting it into a list of words (split at each space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45323639-1dea-423c-9dad-e8c88a3aa2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"I ain't got much sleeping last-night. Don't you think 3 hours' sleep is enough?\"\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf1ded-4149-41c1-9fae-0524317be02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = # Hint, use .split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58414c1-ba48-42d4-87c5-61265583be8b",
   "metadata": {},
   "source": [
    "### Solution Here\n",
    "<details>\n",
    "  <summary>Click to reveal answer. </summary>\n",
    "\n",
    "```python\n",
    "tokens = test_string.split()\n",
    "print(tokens)\n",
    "```\n",
    "(You still have to copy paste this code and run it)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ade1ee-55e2-448f-a2ca-587be560ee42",
   "metadata": {},
   "source": [
    "## Now tokenize all the reviews in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8abbaa-9fb1-4999-9c82-c4316059567e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steam[\"basic_tokenize\"] = steam[\"user_review\"].apply(lambda review: review #Apply your tokenization to the reviews here)\n",
    "display(steam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dc5e0-81c2-48b7-a557-e5c6bb1dcb8e",
   "metadata": {},
   "source": [
    "### Solution Here\n",
    "<details>\n",
    "  <summary>Click to reveal answer. </summary>\n",
    "\n",
    "```python\n",
    "steam[\"basic_tokenize\"] = steam[\"user_review\"].apply(lambda review: review.split(\" \"))\n",
    "display(steam)\n",
    "```\n",
    "(You still have to copy paste this code and run it)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bde5c-da97-44ac-ac5f-6284f4218171",
   "metadata": {},
   "source": [
    "## Let's plot what kind of tokens were made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9824ceb-52dd-409c-a8e1-fac907af97a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "steam[\"basic_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Total: Tokenized word frequency')\n",
    "plt.subplot(3, 1, 2)\n",
    "steam[steam[\"user_suggestion\"]==1][\"basic_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Recommended: Tokenized word frequency')\n",
    "plt.subplot(3, 1, 3)\n",
    "ax = steam[steam[\"user_suggestion\"]==0][\"basic_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Not Recommended: Tokenized word frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f6136-775f-4d53-8636-7b6ba2b09db3",
   "metadata": {},
   "source": [
    "## Let's now turn these tokens into something a model can comprehend (numbers)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd2a8e-63a3-417f-86c1-1742b121bead",
   "metadata": {},
   "source": [
    "### X is the input (tokens), y is what we try to predict (1 = Recommend, 0 = Does not recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b3073-74a7-48a2-b4fa-8f6dffd0e867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(steam[\"basic_tokenize\"].values)\n",
    "y = steam[\"user_suggestion\"]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8d90d-5ba0-40dc-9450-6d4094a87054",
   "metadata": {},
   "source": [
    "### Let's split our data into train and test sets and train our Naive Bayes Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8311be4-5d34-4625-9c10-929949d52258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76f246-9ca0-4977-b4e1-643d5db39486",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d29234-2d63-4849-8a96-ea754097b850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#display(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4407680-5b5c-4b85-8713-1c68b1919d65",
   "metadata": {},
   "source": [
    "## Test the model for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a2949-6471-4050-b3ae-89902f3749f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_basic_model(game_review):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = game_review.split(\" \")\n",
    "    mat = [[int(mlb.classes_[i] in tokens) for i in range(len(mlb.classes_))]]\n",
    "    if model.predict(mat).value == 1:\n",
    "        return f\"Model predicts Recommend. Tokens: {tokens}\"\n",
    "    else:\n",
    "        return f\"Model predicts Does Not Recommend. Tokens: {tokens}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524eb540-0493-45a0-a299-febebf0e6254",
   "metadata": {},
   "source": [
    "### Type in any hypothetical game review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458821ca-089a-481d-bf32-0bc7e551ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_basic_model(\"This game is amazing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac79acd-300a-4496-9d39-cda926fd9ec6",
   "metadata": {},
   "source": [
    "# Improving the model: Tokenize better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc05337-c9d4-4759-85f5-25832f5af9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_string = \"I ain't got much sleeping last-night. Don't you think 3 hours' sleep is enough?\"\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9456e40-2c23-4e4c-b7d0-11aa8f3f275f",
   "metadata": {},
   "source": [
    "### Split the text into more detail using nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b6576-0f8b-4152-8678-025c4f7fddb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(test_string)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb094f5a-da41-400e-890f-3a67f3cd5a27",
   "metadata": {},
   "source": [
    "### Stop words: Frequent words that don't carry much meaning (Using stopwords)\n",
    "Try to remove these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf5cd5-df6c-446b-9ccd-49c8a9f52c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e22723-01f8-46f2-a927-e0432f04eee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_tokens = []\n",
    "for token in tokens:\n",
    "    if not token in stop_words:\n",
    "        new_tokens.append(token)\n",
    "print(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e451d17-c25b-4c8a-80a9-7f8e1e2d7e30",
   "metadata": {},
   "source": [
    "### Perform stemming to homogenize same words with different endings (using PorterStemmer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5244776-60a5-4f54-b9a0-cf7d75259149",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_tokens = []\n",
    "for token in new_tokens:\n",
    "    newer_tokens.append(PorterStemmer().stem(token))\n",
    "print(newer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cdb63-5e6c-4749-925f-ab520eed38b4",
   "metadata": {},
   "source": [
    "### Remove punctuation (using string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce63fc-d747-4629-a60d-4b82900a495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cb687-530f-450d-b3fb-aac52d978607",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tokens = []\n",
    "for token in newer_tokens:\n",
    "    if not token in string.punctuation:\n",
    "        final_tokens.append(token)\n",
    "print(final_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818e668-959c-427d-a564-21a44e45cd2d",
   "metadata": {},
   "source": [
    "## Now Apply these techniques on the entire DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed627b-1304-419d-a650-99861e83d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "steam[\"advanced_tokenize\"] = steam[\"user_review\"].apply(lambda review: review #You could apply your operations here, or in multiple rounds using for loops)\n",
    "display(steam[\"advanced_tokenize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f0223-5468-4056-9198-07a05cb06398",
   "metadata": {},
   "source": [
    "### Solution Here\n",
    "<details>\n",
    "  <summary>Click to reveal answer. </summary>\n",
    "\n",
    "```python\n",
    "stop_words = set(stopwords.words('english'))\n",
    "steam[\"advanced_tokenize\"] = steam[\"user_review\"].apply(lambda review: list(filter(lambda token: token not in string.punctuation, [PorterStemmer().stem(word) for word in nltk.word_tokenize(review) if word.lower() not in stop_words])))\n",
    "display(steam[\"advanced_tokenize\"])\n",
    "```\n",
    "(You still have to copy paste this code and run it)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4349e8-009e-44ad-ae1b-9326a73f8d4b",
   "metadata": {},
   "source": [
    "## Let's see what kinds of tokens we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3836d1-d902-4cdb-8b93-5c528b10f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "steam[\"advanced_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Total: Tokenized word frequency')\n",
    "plt.subplot(3, 1, 2)\n",
    "steam[steam[\"user_suggestion\"]==1][\"advanced_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Recommended: Tokenized word frequency')\n",
    "plt.subplot(3, 1, 3)\n",
    "ax = steam[steam[\"user_suggestion\"]==0][\"advanced_tokenize\"].explode().value_counts().head(10).plot(kind='bar', title='Not Recommended: Tokenized word frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d4202-a8d0-4bb3-a1d5-fa7eb96904c1",
   "metadata": {},
   "source": [
    "## Create X and y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693142dd-8dd8-4220-8f36-2fdcbcde6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "X = mlb.fit_transform(steam[\"advanced_tokenize\"].values)\n",
    "y = steam[\"user_suggestion\"]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46446a21-271c-4479-b04b-5b26367426d2",
   "metadata": {},
   "source": [
    "## Split Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135170d-358a-4aeb-8042-d6e68b0ce892",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17a432-1550-4bda-a5c0-f6d431611145",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c10423-426f-48fe-9a58-de36a07378c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#display(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310bb907-91e1-4f69-b222-eecee759df88",
   "metadata": {},
   "source": [
    "## Try it out yourself with your own reviews!\n",
    "(Make sure you tokenize the words the same way in this function as you did when you trained the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aac0bd-bec9-4885-aa51-17c1ce52e24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_advanced_model(game_review):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = list(filter(lambda token: token not in string.punctuation, [PorterStemmer().stem(word) for word in nltk.word_tokenize(game_review.translate(string.punctuation)) if word.lower() not in stop_words]))\n",
    "    print(tokens)\n",
    "    mat = [[int(mlb.classes_[i] in tokens) for i in range(len(mlb.classes_))]]\n",
    "    if model.predict(mat).value == 1:\n",
    "        return f\"Model predicts Recommend. Tokens: {tokens}\"\n",
    "    else:\n",
    "        return f\"Model predicts Does Not Recommend. Tokens: {tokens}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55009f6-3e9c-4971-be4e-c7a264c3abf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try_advanced_model(\"This game is amazing!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
